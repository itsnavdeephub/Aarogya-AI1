package com.navdeep.aarogyaaitemp

import android.app.Activity
import android.content.Intent
import android.content.pm.PackageManager
import android.media.MediaPlayer
import android.os.Bundle
import android.speech.RecognitionListener
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.speech.tts.TextToSpeech
import android.speech.tts.Voice
import androidx.activity.compose.rememberLauncherForActivityResult
import androidx.activity.result.contract.ActivityResultContracts
import androidx.compose.foundation.background
import androidx.compose.foundation.layout.* // Kept for now, will address if error persists
import androidx.compose.foundation.rememberScrollState
import androidx.compose.foundation.shape.RoundedCornerShape
import androidx.compose.foundation.verticalScroll
import androidx.compose.material.icons.Icons
import androidx.compose.material.icons.filled.* // Kept for now, will address if error persists
import androidx.compose.material3.* // Kept for now, will address if error persists
import androidx.compose.runtime.Composable
import androidx.compose.runtime.DisposableEffect
import androidx.compose.runtime.getValue
import androidx.compose.runtime.mutableStateOf
import androidx.compose.runtime.remember
import androidx.compose.runtime.rememberCoroutineScope
import androidx.compose.runtime.setValue
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.platform.LocalContext
import androidx.compose.ui.text.TextStyle
import androidx.compose.ui.tooling.preview.Preview
import androidx.compose.ui.unit.dp
import androidx.compose.ui.unit.sp
import androidx.core.content.ContextCompat
import android.Manifest
import com.google.accompanist.permissions.ExperimentalPermissionsApi
import com.google.accompanist.permissions.rememberPermissionState
import com.navdeep.aarogyaaitemp.ui.theme.AarogyaAITempTheme
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.delay
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import java.io.File
import java.io.FileOutputStream
import java.io.IOException
import java.util.Locale
import java.util.UUID
// Google Cloud Text-to-Speech imports
import com.google.cloud.texttospeech.v1.AudioConfig
import com.google.cloud.texttospeech.v1.AudioEncoding
import com.google.cloud.texttospeech.v1.SynthesisInput
import com.google.cloud.texttospeech.v1.TextToSpeechClient
import com.google.cloud.texttospeech.v1.VoiceSelectionParams
import com.google.firebase.BuildConfig
// API imports
import retrofit2.Call
import retrofit2.Response
import com.navdeep.aarogyaaitemp.GeminiRequest
import com.navdeep.aarogyaaitemp.Content
import com.navdeep.aarogyaaitemp.Part
import com.navdeep.aarogyaaitemp.GeminiService
import com.navdeep.aarogyaaitemp.GeminiResponse
import com.navdeep.aarogyaaitemp.Candidate

// âœ… Proper API key reference
// This comment is added to trigger a rebuild

@OptIn(ExperimentalMaterial3Api::class)
@Composable
fun ChatScreen(onNavigateToSecond: () -> Unit, onNavigateToInfo: () -> Unit) {
    var input by remember { mutableStateOf("") }
    var response by remember { mutableStateOf("") }
    val scope = rememberCoroutineScope()

    // Read Gemini API key from BuildConfig
    val apiKey = "AIzaSyAXoVey8w02uzmUJUzf_GVDq9qh6TGK1oU" // Corrected to use BuildConfig
    val api = remember { RetrofitClient.getInstance() }
    val context = LocalContext.current
    var tts: TextToSpeech? by remember { mutableStateOf(null) } // Android's TTS for fallback
    var mediaPlayer: MediaPlayer? by remember { mutableStateOf(null) }

    // TTS state management
    var isPlaying by remember { mutableStateOf(false) }
    var isPaused by remember { mutableStateOf(false) }
    
    // Cooldown state to prevent frequent requests
    var lastRequestTime by remember { mutableStateOf(0L) }
    val requestCooldown = 2000L // 2 seconds cooldown (adjusted from 5 seconds for potentially faster interaction)
    
    // Processing state
    var isProcessing by remember { mutableStateOf(false) }
    
    // Speech recognition states
    var isListening by remember { mutableStateOf(false) }
    var speechResult by remember { mutableStateOf("") }
    var speechErrorMessage by remember { mutableStateOf("") }

    // Request microphone permission
    val microphonePermissionState = rememberPermissionState(
        permission = android.Manifest.permission.RECORD_AUDIO
    )

    // Function to read Google API credentials from assets (if needed for Cloud TTS, ensure file exists)
    // fun getGoogleApiCredentials(): String { ... } // This function is defined but not explicitly used in the provided Cloud TTS flow

    val speechRecognizer = remember { SpeechRecognizer.createSpeechRecognizer(context) }
    var isSpeechAvailable by remember { mutableStateOf(false) }

    fun selectBestVoiceForLocale(locale: Locale) {
        tts?.let { textToSpeech ->
            val availableVoices = textToSpeech.voices
            // Prioritize Neural2 voices first, then Wavenet, then standard high quality voices
            val preferredVoice = availableVoices.find {
                it.locale == locale && it.name.contains("neural", true)
            } ?: availableVoices.find { 
                it.locale == locale && it.name.contains("wavenet", true) 
            } ?: availableVoices.find {
                it.locale == locale && (it.quality == Voice.QUALITY_HIGH)
            } ?: availableVoices.find { 
                it.locale == locale 
            } ?: availableVoices.find { 
                it.locale.language == locale.language // Find any voice with the same language
            } ?: availableVoices.find { 
                it.locale == Locale.US || it.locale.language == "en" 
            }
            preferredVoice?.let { textToSpeech.voice = it }
        }
    }

    // Improved speech recognition listener
    val speechRecognitionListener = object : RecognitionListener {
        override fun onReadyForSpeech(params: Bundle?) {}
        
        override fun onBeginningOfSpeech() {
            isListening = true
            speechErrorMessage = ""
        }
        
        override fun onRmsChanged(rmsdB: Float) {}
        
        override fun onBufferReceived(buffer: ByteArray?) {}
        
        override fun onEndOfSpeech() {
            isListening = false
        }
        
        override fun onError(error: Int) {
            isListening = false
            when (error) {
                SpeechRecognizer.ERROR_NO_MATCH -> {
                    speechErrorMessage = "No speech detected. Please try again."
                }
                SpeechRecognizer.ERROR_SPEECH_TIMEOUT -> {
                    speechErrorMessage = "No speech input detected. Please try again."
                }
                SpeechRecognizer.ERROR_NETWORK -> {
                    speechErrorMessage = "Network error. Please check your connection."
                }
                SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS -> {
                    speechErrorMessage = "Please grant microphone permissions for speech recognition."
                }
                else -> {
                    speechErrorMessage = "Speech recognition error: $error. Please try again."
                }
            }
        }
        
        override fun onResults(results: Bundle?) {
            isListening = false
            speechResult = "" // Clear the speech result
            speechErrorMessage = ""
            val matches = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
            if (!matches.isNullOrEmpty()) {
                // Use the first (most confident) result
                input = matches[0]
            }
        }
        
        override fun onPartialResults(partialResults: Bundle?) {
            // Show partial results as they are recognized
            val partial = partialResults?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
            if (!partial.isNullOrEmpty()) {
                speechResult = partial[0]
            }
        }
        
        override fun onEvent(eventType: Int, params: Bundle?) {}
    }

    DisposableEffect(Unit) {
        isSpeechAvailable = context.packageManager.hasSystemFeature(PackageManager.FEATURE_MICROPHONE) &&
                Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).resolveActivity(context.packageManager) != null

        // Set up speech recognizer with improved listener
        speechRecognizer.setRecognitionListener(speechRecognitionListener)

        tts = TextToSpeech(context) { status: Int -> // Explicitly typed 'status'
            if (status == TextToSpeech.SUCCESS) {
                val result = tts?.setLanguage(Locale.getDefault())
                if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
                    tts?.setLanguage(Locale.US)
                }
                selectBestVoiceForLocale(Locale.getDefault())
            }
        }
        onDispose {
            speechRecognizer.destroy()
            tts?.stop()
            tts?.shutdown()
            mediaPlayer?.release()
            mediaPlayer = null
        }
    }

    // Improved speech recognition launcher
    val speechRecognizerLauncher = rememberLauncherForActivityResult(
        contract = ActivityResultContracts.StartActivityForResult()
    ) { result -> 
        if (result.resultCode == Activity.RESULT_OK) {
            val matches = result.data?.getStringArrayListExtra(RecognizerIntent.EXTRA_RESULTS)
            matches?.let { if (it.isNotEmpty()) input = it[0] }
        }
    }

    // Enhanced language detection function
    fun detectLanguage(text: String): Locale {
        val hasLatinChars = text.any { it in 'A'..'Z' || it in 'a'..'z' }
        val hasHindiChars = text.any { it in '\u0900'..'\u097F' }
        val hasArabicChars = text.any { it in '\u0600'..'\u06FF' }
        val hasChineseChars = text.any { it in '\u4e00'..'\u9fff' }
        val hasPunjabiChars = text.any { it in '\u0A00'..'\u0A7F' } // Punjabi character range
        
        return when {
            hasPunjabiChars -> Locale.forLanguageTag("pa-IN") // Punjabi locale
            hasHindiChars -> Locale.forLanguageTag("hi-IN")
            hasArabicChars -> Locale.forLanguageTag("ar")
            hasChineseChars -> Locale.forLanguageTag("zh-CN")
            hasLatinChars -> Locale.ENGLISH
            else -> Locale.getDefault()
        }
    }

    fun buildMedicalPrompt(input: String): String {
        return "As a medical assistant, please provide helpful and accurate information about the following health concern: $input\n\n" +
                "Please ensure your response is:\n" +
                "1. Empathetic and supportive\n" +
                "2. Based on reliable medical knowledge\n" +
                "3. Not a substitute for professional medical advice\n" +
                "4. Encourage seeking professional help when appropriate\n\n" +
                "5. Also ask more question to get more information about the concern of the health of patient\n\n" +
                "6. do not use '*' in the response which you give to the patient about the health of patient\n \n\n" +
                "7. without saying any thing in the start of the response just ask questions about the problem of patient\n \n\n" +
                "8. Ask questions one by one and wait for the answer of the patient\n" +
                "9. Give the response in the same language as the question asked in which language the question is asked\n \n" +
                "Response:"
    }

    fun speakTextWithEnhancedSettings(text: String) {
        tts?.let { textToSpeech ->
            if (text.isNotEmpty()) {
                val utteranceId = UUID.randomUUID().toString()
                val detectedLocale = detectLanguage(text)
                val result = textToSpeech.setLanguage(detectedLocale)
                if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
                    textToSpeech.setLanguage(Locale.US)
                } else {
                    selectBestVoiceForLocale(detectedLocale)
                }
                val params = Bundle().apply {
                    putString(TextToSpeech.Engine.KEY_PARAM_UTTERANCE_ID, utteranceId)
                    putString(TextToSpeech.Engine.KEY_PARAM_VOLUME, "1.0")
                }
                when (detectedLocale.language) {
                    "hi" -> { textToSpeech.setSpeechRate(0.85f); textToSpeech.setPitch(1.0f) }
                    "ar" -> { textToSpeech.setSpeechRate(0.75f); textToSpeech.setPitch(0.9f) }
                    "pa" -> { textToSpeech.setSpeechRate(0.8f); textToSpeech.setPitch(1.0f) } // Punjabi settings
                    else -> { textToSpeech.setSpeechRate(1.0f); textToSpeech.setPitch(1.0f) }
                }
                textToSpeech.speak(text, TextToSpeech.QUEUE_FLUSH, params, utteranceId)
            }
        }
    }

    fun stopAllTTSPlayback() {
        tts?.stop()
        mediaPlayer?.let { mp ->
            if (mp.isPlaying) mp.stop()
            mp.release()
        }
        mediaPlayer = null
        isPlaying = false
        isPaused = false
    }

    fun speakTextWithCloudTTS(text: String) {
        if (text.isEmpty()) return
        stopAllTTSPlayback()

        scope.launch(Dispatchers.IO) {
            var ttsClient: TextToSpeechClient? = null
            val audioFile = File(context.cacheDir, "cloud_tts_output.mp3")
            try {
                // Consider using service account credentials for TextToSpeechClient if not relying on ADC
                // val credentialsProvider = FixedCredentialsProvider.create(ServiceAccountCredentials.fromStream(context.assets.open("google-credentials.json")))
                // ttsClient = TextToSpeechClient.create(TextToSpeechSettings.newBuilder().setCredentialsProvider(credentialsProvider).build())
                ttsClient = TextToSpeechClient.create() // Assumes Application Default Credentials are set up or you have other auth configured
                val inputBuilder = SynthesisInput.newBuilder().setText(text)
                val detectedLocale = detectLanguage(text)
                val voiceBuilder = VoiceSelectionParams.newBuilder()
                    .setLanguageCode(detectedLocale.toLanguageTag())
                
                // Using the most advanced Neural2 voice models where available
                when (detectedLocale.language) {
                    "hi" -> voiceBuilder.setName("hi-IN-Neural2-D") // More advanced Neural2 voice for Hindi with better clarity
                    "ar" -> voiceBuilder.setName("ar-XA-Neural2-C") // More advanced Neural2 voice for Arabic with enhanced naturalness
                    "zh" -> voiceBuilder.setName("cmn-CN-Neural2-C") // More advanced Neural2 voice for Chinese with improved pronunciation
                    "pa" -> voiceBuilder.setName("pa-IN-Neural2-A") // Neural2 voice for Punjabi
                    else -> voiceBuilder.setName("en-US-Neural2-J") // Most advanced Neural2 voice for English with highest quality
                }
                
                // Using higher quality audio encoding with enhanced settings
                val audioConfig = AudioConfig.newBuilder()
                    .setAudioEncoding(AudioEncoding.MP3)
                    .setSpeakingRate(1.0) // Normal speaking rate
                    .setPitch(0.0) // Default pitch for most natural sound
                    .setVolumeGainDb(0.0) // Normal volume
                    .setSampleRateHertz(24000) // Higher sample rate for better quality
                    .build()
                val cloudResponse = ttsClient.synthesizeSpeech(inputBuilder.build(), voiceBuilder.build(), audioConfig)
                
                FileOutputStream(audioFile).use { fos ->
                    fos.write(cloudResponse.audioContent.toByteArray())
                }

                withContext(Dispatchers.Main) {
                    mediaPlayer = MediaPlayer().apply {
                        setDataSource(audioFile.absolutePath)
                        prepareAsync()
                        setOnPreparedListener {
                            start()
                            isPlaying = true
                            isPaused = false
                        }
                        setOnCompletionListener {
                            stopAllTTSPlayback() // Releases media player and resets flags
                            audioFile.delete() // Clean up the audio file
                        }
                        setOnErrorListener { _, _, _ ->
                            stopAllTTSPlayback()
                            audioFile.delete()
                            speakTextWithEnhancedSettings(text) // Fallback to Android TTS
                            true
                        }
                    }
                }
            } catch (e: IOException) {
                e.printStackTrace()
                speakTextWithEnhancedSettings(text) // Fallback to Android's TTS if Cloud TTS fails
            } finally {
                ttsClient?.shutdown()
            }
        }
    }

    // Improved speech recognition function
    fun startListening() {
        if (!isListening) {
            speechResult = ""
            speechErrorMessage = ""
            
            val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
                putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
                putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault())
                putExtra(RecognizerIntent.EXTRA_PROMPT, "Speak now...")
                // Enhanced settings for better accuracy
                putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 5) // Get multiple results
                putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true) // Enable partial results
                putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS, 1500)
                putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS, 1500)
            }
            
            try {
                speechRecognizer.startListening(intent)
            } catch (e: Exception) {
                e.printStackTrace()
                speechErrorMessage = "Failed to start speech recognition: ${e.message}"
                // Fallback to the activity result approach
                speechRecognizerLauncher.launch(intent)
            }
        } else {
            // Stop listening if already listening
            try {
                speechRecognizer.stopListening()
            } catch (e: Exception) {
                e.printStackTrace()
            }
            isListening = false
        }
    }
    
    fun stopListening() {
        if (isListening) {
            try {
                speechRecognizer.stopListening()
            } catch (e: Exception) {
                e.printStackTrace()
            }
            isListening = false
        }
    }
    
    // Send request function remains unchanged
    fun sendRequest() {
            
            speechResult = ""
            speechErrorMessage = ""
            
            val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
                putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
                putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault())
                putExtra(RecognizerIntent.EXTRA_PROMPT, "Speak now...")
                // Enhanced settings for better accuracy
                putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 5) // Get multiple results
                putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true) // Enable partial results
                putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_COMPLETE_SILENCE_LENGTH_MILLIS, 1500)
                putExtra(RecognizerIntent.EXTRA_SPEECH_INPUT_POSSIBLY_COMPLETE_SILENCE_LENGTH_MILLIS, 1500)
            }
            
            try {
                speechRecognizer.startListening(intent)
            } catch (e: Exception) {
                e.printStackTrace()
                speechErrorMessage = "Failed to start speech recognition: ${e.message}"
                // Fallback to the activity result approach
                speechRecognizerLauncher.launch(intent)
            }
        } else {
            // Stop listening if already listening
            try {
                speechRecognizer.stopListening()
            } catch (e: Exception) {
                e.printStackTrace()
            }
            isListening = false
        }
    }

    fun stopListening() {
        if (isListening) {
            try {
                speechRecognizer.stopListening()
            } catch (e: Exception) {
                e.printStackTrace()
            }
            isListening = false
        }
    }

    fun sendRequest() {
        if (input.isEmpty() || isProcessing) return
        val currentTime = System.currentTimeMillis()
        if (currentTime - lastRequestTime < requestCooldown) return
        lastRequestTime = currentTime

        isProcessing = true
        scope.launch(Dispatchers.IO) {
            val request = GeminiRequest(
                contents = listOf(
                    Content(
                        parts = listOf(
                            Part(
                                text = input
                            )
                        )
                    )
                )
            )
            val call: Call<GeminiResponse> = api.generateContent(apiKey, request)
            try {
                val apiResponse: Response<GeminiResponse> = call.execute()
                if (apiResponse.isSuccessful) {
                    val responseBody = apiResponse.body()
                    val candidate = responseBody?.candidates?.firstOrNull()
                    val content = candidate?.content
                    val text = content?.parts?.firstOrNull()?.text
                    withContext(Dispatchers.Main) {
                        response = text ?: ""
                        speakTextWithCloudTTS(text ?: "")
                    }
                } else {
                    withContext(Dispatchers.Main) {
                        response = "Error: ${apiResponse.code()}"
                    }
                }
            } catch (e: IOException) {
                e.printStackTrace()
                withContext(Dispatchers.Main) {
                    response = "Network error"
                }
            } finally {
                isProcessing = false
            }
        }
    }

    Scaffold(
        topBar = {
            CenterAlignedTopAppBar(
                title = { Text("Aarogya AI", color = Color.White, fontSize = 24.sp) },
                colors = TopAppBarDefaults.centerAlignedTopAppBarColors(
                    containerColor = Color(0xFF0C1117)
                )
            )
        },
        bottomBar = {
            NavigationBar(containerColor = Color(0xFF0C1117)) {
                NavigationBarItem(
                    selected = true, onClick = { },
                    icon = { Icon(Icons.Default.Home, "Home", tint = Color.Green) },
                    label = { Text("Home", color = Color.White) }
                )
                NavigationBarItem(
                    selected = false, onClick = { onNavigateToSecond() },
                    icon = { Icon(Icons.Default.LocalHospital, "Hospitals", tint = Color.Green) },
                    label = { Text("Hospitals", color = Color.White) }
                )
                NavigationBarItem(
                    selected = false, onClick = { onNavigateToInfo() },
                    icon = { Icon(Icons.Default.Info, "Info", tint = Color.Green) },
                    label = { Text("Info", color = Color.White) }
                )
            }
        },
        containerColor = Color(0xFF0C1117)
    ) { padding ->
        Column(
            modifier = Modifier
                .fillMaxSize()
                .background(Color(0xFF0C1117))
                .padding(padding),
            horizontalAlignment = Alignment.CenterHorizontally
        ) {
            Spacer(modifier = Modifier.height(20.dp))
            OutlinedTextField(
                value = when {
                    speechErrorMessage.isNotEmpty() -> speechErrorMessage
                    isListening && speechResult.isNotEmpty() -> speechResult
                    else -> input
                },
                onValueChange = { 
                    input = it
                    // If user starts typing while listening, stop listening
                    if (isListening) {
                        stopListening()
                    }
                },
                label = { Text("How do you feel today?", color = Color.White) },
                textStyle = TextStyle(color = Color.White),
                modifier = Modifier.fillMaxWidth().padding(16.dp),
                trailingIcon = {
                    if (isSpeechAvailable) {
                        IconButton(onClick = {
                            startListening()
                        }) {
                            Icon(
                                imageVector = if (isListening) Icons.Default.MicOff else Icons.Default.Mic,
                                contentDescription = if (isListening) "Stop listening" else "Speech to text",
                                tint = when {
                                    isListening -> Color.Red
                                    speechErrorMessage.isNotEmpty() -> Color.Yellow
                                    else -> Color.White
                                }
                            )
                        }
                    }
                }
            )
            Spacer(modifier = Modifier.height(20.dp))

            Row(modifier = Modifier.fillMaxWidth(), horizontalArrangement = Arrangement.SpaceEvenly) {
                Button(
                    onClick = {
                        val currentTime = System.currentTimeMillis()
                        if (isProcessing || (currentTime - lastRequestTime < requestCooldown)) {
                            if (!isProcessing) { // Only show cooldown message if not already processing
                                val remainingTime = requestCooldown - (currentTime - lastRequestTime)
                                response = "Please wait ${remainingTime / 1000 + 1} seconds before sending another request."
                            }
                            return@Button
                        }
                        
                        lastRequestTime = currentTime
                        isProcessing = true
                        response = "" // Clear previous response or show "Processing..."
                        scope.launch {
                            try {
                                val enhancedPrompt = buildMedicalPrompt(input)
                                val contents = listOf(Content(parts = listOf(Part(text = enhancedPrompt)))) // Simplified prompt for Gemini
                                val request = GeminiRequest(contents = contents)

                                var retries = 0
                                val maxRetries = 3
                                val baseDelay = 1000L // 1 second base delay
                                var apiResponseSuccessful = false
                                
                                while (retries < maxRetries && !apiResponseSuccessful) {
                                    if (retries > 0) {
                                        response = "Retrying... (attempt ${retries + 1}/$maxRetries)"
                                        delay(baseDelay * (1L shl retries)) // Exponential backoff
                                    }
                                    try {
                                        val call = api.generateContent(apiKey, request) // apiKey from BuildConfig
                                        val res = withContext(Dispatchers.IO) { call.execute() }

                                        if (res.isSuccessful) {
                                            response = res.body()
                                                ?.candidates
                                                ?.firstOrNull()
                                                ?.content
                                                ?.parts
                                                ?.firstOrNull()
                                                ?.text ?: "No valid response received."
                                            apiResponseSuccessful = true
                                        } else {
                                            response = "Error: ${res.code()} - ${res.message()}. Check logs for details."
                                            // Log error for more details
                                            android.util.Log.e("API_CALL_ERROR", "Code: ${res.code()}, Message: ${res.message()}, Body: ${res.errorBody()?.string()}")
                                            if (res.code() == 429) { // Too Many Requests
                                                // Handled by retry loop with backoff
                                            } else {
                                                // For other errors, might not be worth retrying without changes
                                                break
                                            }
                                        }
                                    } catch (e: Exception) {
                                        e.printStackTrace()
                                        response = "Error: ${e.message}. Check logs for details."
                                        // Log error for more details
                                        android.util.Log.e("API_CALL_ERROR", "Exception: ${e.message}", e)
                                    }
                                }
                            } finally {
                                isProcessing = false
                            }
                        }
                    },
                    modifier = Modifier.weight(1f)
                ) {
                    Text("Send", color = Color.White)
                }
                // Replaced Speak button with Play and Pause buttons
                if (isPlaying && !isPaused) {
                    Button(
                        onClick = {
                            // Pause functionality
                            mediaPlayer?.pause()
                            tts?.stop()
                            isPaused = true
                        },
                        modifier = Modifier.weight(0.5f)
                    ) {
                        Text("Pause", color = Color.White)
                    }
                } else {
                    Button(
                        onClick = {
                            if (isPaused) {
                                // Resume functionality
                                mediaPlayer?.start()
                                isPaused = false
                                isPlaying = true
                            } else {
                                // Play functionality
                                speakTextWithCloudTTS(response)
                            }
                        },
                        modifier = Modifier.weight(0.5f)
                    ) {
                        Text(if (isPaused) "Resume" else "Play", color = Color.White)
                    }
                }
            }
            Spacer(modifier = Modifier.height(20.dp))
            Text(
                text = response,
                color = Color.White,
                modifier = Modifier
                    .fillMaxWidth()
                    .padding(16.dp)
                    .verticalScroll(rememberScrollState()),
                style = TextStyle(fontSize = 16.sp)
            )
        }
    }
}

@Preview(showBackground = true)
@Composable
fun ChatScreenPreview() {
    AarogyaAITempTheme {
        ChatScreen(onNavigateToSecond = {}, onNavigateToInfo = {})
    }
}
